import re
import json
from bs4 import BeautifulSoup
import os

def analyze_html():
    """–ê–Ω–∞–ª—ñ–∑—É—î –∑–±–µ—Ä–µ–∂–µ–Ω–∏–π HTML"""
    try:
        if not os.path.exists("debug_playwright.html"):
            print("‚ùå –§–∞–π–ª debug_playwright.html –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
            return
        
        with open("debug_playwright.html", "r", encoding="utf-8") as f:
            html = f.read()
        
        print("üìä –ê–Ω–∞–ª—ñ–∑ HTML —Å—Ç–æ—Ä—ñ–Ω–∫–∏ Otodom...")
        print(f"üìÑ –†–æ–∑–º—ñ—Ä HTML: {len(html)} —Å–∏–º–≤–æ–ª—ñ–≤")
        
        # –®—É–∫–∞—î–º–æ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞
        keywords = ['photo', 'image', 'gallery', 'zdjecie', 'zdjƒôcie', 'foto', 'picture']
        found_keywords = []
        
        for keyword in keywords:
            count = html.lower().count(keyword)
            if count > 0:
                found_keywords.append(f"{keyword}({count})")
        
        print(f"üîç –ó–Ω–∞–π–¥–µ–Ω—ñ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞: {', '.join(found_keywords)}")
        
        # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å—Ç–æ—Ä—ñ–Ω–∫–∏
        soup = BeautifulSoup(html, 'html.parser')
        
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—Å—ñ —Ç–µ–≥–∏
        all_tags = [tag.name for tag in soup.find_all()]
        tag_counts = {}
        for tag in all_tags:
            tag_counts[tag] = tag_counts.get(tag, 0) + 1
        
        print(f"üè∑Ô∏è –¢–µ–≥–∏ –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ: {dict(sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)[:10])}")
        
        # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ script —Ç–µ–≥–∏
        scripts = soup.find_all('script')
        print(f"üìú –ó–Ω–∞–π–¥–µ–Ω–æ {len(scripts)} script —Ç–µ–≥—ñ–≤")
        
        data_scripts = []
        for i, script in enumerate(scripts):
            script_content = script.string
            if script_content and len(script_content) > 50:
                # –®—É–∫–∞—î–º–æ –¥–∞–Ω—ñ –≤ script
                if any(keyword in script_content.lower() for keyword in ['image', 'photo', 'window.__', 'JSON', 'props']):
                    data_scripts.append((i, len(script_content)))
                    
                    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ URL –≤ script
                    urls = re.findall(r'https?://[^\s"\'<>]+', script_content)
                    otodom_urls = [url for url in urls if 'otodom' in url]
                    if otodom_urls:
                        print(f"üéØ Script {i}: {len(otodom_urls)} Otodom URL")
                        for url in otodom_urls[:3]:
                            if any(ext in url.lower() for ext in ['.jpg', '.jpeg', '.png', '.webp']):
                                print(f"   üì∏ {url[:100]}...")
        
        print(f"üìä Script —Ç–µ–≥–∏ –∑ –¥–∞–Ω–∏–º–∏: {data_scripts}")
        
        # –®—É–∫–∞—î–º–æ img —Ç–µ–≥–∏
        img_tags = soup.find_all('img')
        print(f"üñºÔ∏è –ó–Ω–∞–π–¥–µ–Ω–æ {len(img_tags)} img —Ç–µ–≥—ñ–≤")
        
        otodom_images = []
        for img in img_tags[:10]:  # –ü–µ—Ä–µ–≤—ñ—Ä–∏–º–æ –ø–µ—Ä—à—ñ 10
            src = img.get('src', '')
            if src and 'otodom' in src:
                otodom_images.append(src)
                print(f"   üì∏ {src[:100]}...")
        
        # –®—É–∫–∞—î–º–æ meta —Ç–µ–≥–∏
        meta_tags = soup.find_all('meta')
        og_images = []
        for meta in meta_tags:
            prop = meta.get('property', '')
            content = meta.get('content', '')
            if 'image' in prop and content:
                og_images.append(content)
        
        if og_images:
            print(f"üì± OG images: {og_images}")
        
        # –®—É–∫–∞—î–º–æ div —Ç–∞ —ñ–Ω—à—ñ –µ–ª–µ–º–µ–Ω—Ç–∏ –∑ –∫–ª–∞—Å–∞–º–∏
        divs_with_classes = soup.find_all(['div', 'section', 'main'], class_=True)
        unique_classes = set()
        for div in divs_with_classes[:20]:  # –ü–µ—Ä—à—ñ 20
            classes = div.get('class', [])
            unique_classes.update(classes)
        
        print(f"üé® –£–Ω—ñ–∫–∞–ª—å–Ω—ñ –∫–ª–∞—Å–∏ (–ø–µ—Ä—à—ñ 20): {list(unique_classes)[:20]}")
        
        # –®—É–∫–∞—î–º–æ –¥–∞–Ω—ñ –≤ data-–∞—Ç—Ä–∏–±—É—Ç–∞—Ö
        data_elements = soup.find_all(attrs={"data-cy": True})
        data_cy_values = [elem.get('data-cy') for elem in data_elements[:10]]
        if data_cy_values:
            print(f"üîß data-cy –∞—Ç—Ä–∏–±—É—Ç–∏: {data_cy_values}")
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∞–Ω–∞–ª—ñ–∑—É: {e}")

def check_debug_files():
    """–ü–µ—Ä–µ–≤—ñ—Ä—è—î –Ω–∞—è–≤–Ω—ñ—Å—Ç—å debug —Ñ–∞–π–ª—ñ–≤"""
    files = [
        "debug_playwright.html",
        "debug_screenshot.png", 
        "debug_api_response.json",
        "debug_direct_html.html"
    ]
    
    print("üîç –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ debug —Ñ–∞–π–ª—ñ–≤...")
    for file in files:
        if os.path.exists(file):
            size = os.path.getsize(file)
            print(f"‚úÖ {file}: {size} –±–∞–π—Ç")
        else:
            print(f"‚ùå {file}: –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")

if __name__ == "__main__":
    print("üéØ –ê–Ω–∞–ª—ñ–∑ Otodom —Å—Ç–æ—Ä—ñ–Ω–∫–∏")
    print("=" * 50)
    check_debug_files()
    print("=" * 50)
    analyze_html()